\def\la{\text{\em la}}
\def\casa{\text{\em casa}}
\def\grande{\text{\em grande}}

\def\det{{\text{\sc Det}}}
\def\prn{{\text{\sc  Prn}}}
\def\n{{\text{\sc N}}}
\def\v{{\text{\sc V}}}
\def\adj{{\text{\sc Adj}}}

\def\laDet{\la_\det}
\def\laPrn{\la_\prn}
\def\casaN{\casa_\n}
\def\casaV{\casa_\v}
\def\grandeAdj{\grande_\adj}

\def\t#1{\texttt{#1}}
\def\ob#1{\overbrace{ #1 \rule{0pt}{2ex}}}
\def\cgrule#1{{\ttfamily #1}}

\def\defRule{``do not remove the last reading''}


\chapter{CG as a SAT-problem}
\label{chapterCGSAT}

In this chapter, we present CG as a Boolean satisfiability (SAT) problem,
and describe an implementation using a SAT-solver. 
This is attractive for several reasons: formal logic is
well-studied, and serves as an abstract language to reason about the
properties of CG. Constraint rules encoded in logic capture richer
dependencies between the tags than standard CG. 
%; much like in parallel CG, one rule is not a self-contained unit, but a piece in the puzzle.


%So far, we have presented CG and SAT as separate success stories: CG is easy to adopt, even for less-resourced languages, and achieves high F-scores; SAT is used in reducing difficult search problems into a low-level task.
%But is there a reason to combine the two? 

%CG lends itself well to a logical representation. It's all about expressing what is true (`SELECT') and false (`REMOVE'), under certain conditions (`IF').
Applying logic to reductionist grammars has been explored earlier by \cite{lager98,lager_nivre01}, but there has not been, to our knowledge, a full logic-based CG implementation; at the time, logic programming was too slow to be used for tagging or parsing. 
Since those works, SAT-solving techniques have improved significantly \cite{marques_silva2010}, and they are used in domains such as microprocessor design and computational 
biology---these problems easily match or exceed CG in complexity. 
In addition, SAT-solving brings us more practical tools

Thanks to these advances, we were able to revisit the idea and develop it further. 


The content in this chapter is based on \cite{listenmaa_claessen2015}.
As in the original paper, we present a translation of CG rules into logical formulas, and show how to encode it into a SAT-problem.
This work is implemented as an open-source software SAT-CG\footnote{\url{https://github.com/inariksit/cgsat}}. It uses the high-level library SAT+\footnote{\url{https://github.com/koengit/satplus}}, which is based on MiniSAT \cite{een04sat}.
We evaluate SAT-CG against the state of the art, VISL CG-3.
The experimental setup is the same, but we ran the tests again for this thesis: since the writing of  \cite{listenmaa_claessen2015}, we have optimised our program and fixed some bugs; likewise, VISL CG-3 has been updated, and executes faster than what we report in the earlier paper. 
While the absolute numbers have changed, the relative differences between the running time and F-scores remain as in the paper.


\section{Previous work: CG in logic}\label{encoding-in-logic}

\input{chapters/cg-sat-relatedwork}


\section{CG as a SAT-problem}
\label{sec:CGSAT}

First we present the preliminaries: Input=ambiguous clauses; Each reading = variable; Apply rule = create implications on those variables; Goal: find a solution!

Then, we explain different ordering schemes, and discuss conflict handling.

Finally, we evaluate SAT-CG against VISL CG-3, for both F-score and running time.
%: for F-score, we use a 20,000--word Spanish gold standard corpus, and for running time, we use.

\subsection{Preliminaries}

%We have seen in Section~\ref{sec:SAT-intro} how to transform a simple decision task into a SAT-problem. 
%:each animal was represented as a variable, and their restrictions for cohabiting were expressed as clauses; ``if dog, then cat''.
In the following, we translate the disambiguation of a sentence into a SAT-problem.
We demonstrate our encoding with an example in Spanish, shown in Figure~\ref{fig:laCasaGrande}: {\em la casa grande}. % (`the big house'). 
The first word, {\em la}, is ambiguous between a definite article (`the') or an object pronoun (`her'), and the second word, {\em casa}, can be a noun (`house') or a verb form (`marries').
The subsegment {\em la casa} alone can be either a noun phrase, $\laDet \ \casaN$ 
`the house'  or a verb phrase $\laPrn \ \casaV$   `(he/she) marries her'. 
However, the unambiguous adjective, {\em grande} (`big'), disambiguates the whole segment into a noun phrase: `the big house'.

\begin{figure}[h]
\centering
\begin{tabular}{p{0.6cm} l | c | c }
%\multicolumn{2}{c}{}
   & \textbf{Original~analysis} 
                & \textbf{Variables}
                              & \textbf{Default rule} \\ \hline
\t{"<la>"}   &   &            &  {\small \defRule} \\
  & \t{"el" 
  det def f sg}  & $\laDet$   &  \\
  & \t{"lo" 
  prn p3 f sg}   & $\laPrn$   &   $\laDet \vee \laPrn$ \\
\t{"<casa>"} &   &            &   \\
  & \t{"casa" 
  n f sg}        & $\casaN$   &  \\
  & \t{"casar"
   v pri p3 sg}  & $\casaV$   & $\casaN \vee \casaV$  \\
\t{"<grande>"} & &            & \\
  & \t{"grande" 
  adj mf sg}   & $\grandeAdj$ & $\grandeAdj$
\end{tabular}
\caption{Ambiguous segment in Spanish: translation into SAT-variables.}
\label{fig:laCasaGrande}
\end{figure}


% \begin{figure}[h]
% \centering
% \begin{verbatim}
% "<la>"
%         "el" det def f sg
%         "lo" prn p3 f sg
% "<casa>"
%         "casa" n f sg
%         "casar" v pri p3 sg
% "<grande>"
%         "grande" adj mf sg
% \end{verbatim}
% \caption{Ambiguous segment in Spanish.}
% \label{fig:laCasaGrande}
% \end{figure}

\paragraph{Reading}
The readings of the word forms make a natural basis for variables.
We translate a combination of a word form and a reading, such as \texttt{"<la>" ["el" det def f sg]}, into a variable $\laDet$, which represents the possibility that \la{} is a determiner. This example segment gives us five variables: $\{ \laDet , \laPrn , \casaN , \casaV,  \grandeAdj \}$, shown in \ref{fig:laCasaGrande}.

\paragraph{Cohort} As in the original input, the readings are grouped together in cohorts. We need to keep this distinction, for instance, to model {\sc select} rules and cautious context: 
\t{SELECT "casa" n} means, in effect, ``remove $\casaV$'', and \t{IF (-1C prn)} means ``if $\laPrn$ is true and $\laDet$ false''. 
%
Most importantly, we need to make sure that the last reading is not removed. Hence we add the default rule, \defRule, as shown in the third column of \ref{fig:laCasaGrande}. 
These disjunctions ensure that at least one variable in each cohort must be true.



\paragraph{Sentence}
In order to match conditions against analyses, the input needs to be structured as a sentence: the cohorts must follow each other like in the original input, indexed by their absolute position in the sentence. Thus when we apply \texttt{REMOVE v IF (-1 det)} to the cohort $2 \rightarrow [\casaN , \casaV]$, the condition will match on $\laDet$ in cohort 1.


\paragraph{Rule}

Next, we formulate a rule in SAT. A single rule, such as \texttt{REMOVE v IF (-1 det)}, is a template for forming an implication; when given a concrete sentence, it will pick concrete variables by the following algorithm.

\begin{enumerate}
\item Match rule against all cohorts
 \begin{itemize}
    \item[\la:] No target found
    \item[\casa:] Target found in $\casaV$, match conditions to \la
      \begin{itemize}
       \item Condition found in $\laDet$
       \item Create a clause: $\laDet \Rightarrow \neg \casaV \ $ `if \la{} is a determiner, \casa{} is not a verb'
      \end{itemize}
    \item[\grande:] No target found
  \end{itemize}
\item Solve with all clauses: 
  $\{ \ob{\laDet \! \vee \laPrn, \ \casaN \vee \casaV, \  \grandeAdj}^{\text{given by the default rule}}, \ 
      \ob{\laDet \Rightarrow \neg \casaV}^{\t{REMOVE v IF (-1 det)}} \}$
\end{enumerate}

In Appendix~\ref{appendix1}
, we have included a translation of {\sc remove} and {\sc select} rules, with all possible conditions in CG-2 \todo{check if all}. The following examples in this section do not require reading the appendix.

\subsection{Applying a rule}

%Finally, we have all we need to solve the disambiguation problem. Given the clauses presented in step 2, SAT-solver returns a model---this is our disambiguated sentence. 

Finally, we have all we need to disambiguate the segment: the sentence and the constraints encoded as SAT-variables and clauses. The SAT-solver returns a model that satisfies all the clauses presented in step 2.
We started off with all the variables unassigned, and required at least one variable 
in each cohort to be true. In addition, we gave the clause $\laDet \Rightarrow \neg \casaV$.
We can see with bare eye that this problem will have a solution; in fact, multiple ones, 
shown in Figure~\ref{fig:modelsOneRule}.
The verb analysis is removed in the first two models, as required by the presence of $\laDet$. However, the implication may as well be interpreted ``if $\casaV$ may not follow $\laDet$, better remove $\laDet$ instead''; this has happened in Models 3--4. 
We see a third interpretation in Model 5: $\casaV$ may be removed even without 
the presence of $\laDet$. This is possible, because $\laDet \Rightarrow \neg \casaV$ is only an implication, not an equivalence.

\begin{figure}[h]
\centering
$$\begin{array}{ c | c | c | c | c}
\textbf{Model 1}  & \textbf{Model 2}  & \textbf{Model 3} & \textbf{Model 4} & \textbf{Model 5} \\ \hline
 \laDet   &  \laDet  &         &        &        \\
          &  \laPrn  & \laPrn  & \laPrn & \laPrn \\
 \casaN   &  \casaN  & \casaN  &        & \casaN \\
          &          & \casaV  & \casaV &         \\
\grandeAdj & \grandeAdj & \grandeAdj & \grandeAdj & \grandeAdj \\

\end{array}$$
\caption{Possible models for \t{REMOVE v IF (-1 det)}.}
\label{fig:modelsOneRule}
\end{figure}

The reader may notice that this is not a particularly exciting result. A standard CG would just do what it is told and remove the verb, not give 5 different interpretations for a single rule.
But there is power to this property. Now, we add a second rule: \texttt{REMOVE n IF (-1 prn)}, which will form the clause $\laPrn \Rightarrow \neg \casaN$. The new clause
%, together with $\laDet \Rightarrow \neg \casaV$, 
prohibits the combination $\laPrn \ \casaN$, which rules out three models out of five. The disambiguation is shown in Figure~\ref{fig:modelsTwoRules}.

\begin{figure}[h!]
\centering
$$\begin{array}{ c | c }
 \textbf{Model 1}  & \textbf{Model 2}  \\ \hline
 \laDet   &          \\
          &  \laPrn  \\
 \casaN   &          \\
          &  \casaV   \\
\grandeAdj & \grandeAdj \\

\end{array}$$
\caption{Possible models for \t{REMOVE v IF (-1 det)} and \t{REMOVE n IF (-1 prn)}.}
\label{fig:modelsTwoRules}
\end{figure}


After two rules, we only have two models: one with $\laDet \ \casaN$ and other with $\laPrn \ \casaV$. 
%This behaviour corresponds to FSIG: 
In fact, we have accidentally just implemented FSIG \cite{koskenniemi90}, introduced in Section~\ref{sec:ordering}: the rules act in parallel, and if the sentence cannot be fully disambiguated, the remaining uncertainty is modelled as a disjunction of all possible combinations of readings.
In contrast, a sequential CG engine applies each rule individually, and it cannot handle disjunction; its only operation is to manipulate readings in a cohort.
%remove \footnote{In CG-3, we can also add readings to a cohort, and cohorts to a sentence.} readings from a cohort. 
The CG engine would have just applied one of the rules---say, the first one, removed the verb and stopped there. If another rule later in the sequence removes the determiner, there is no way to restore the verb. 

To finish our FSIG example, let us add one more rule: \t{REMOVE v IF (1 adj)}, and the corresponding clause $\grandeAdj \Rightarrow \neg \casaV$. This clause will rule out Model~2 of Figure~\ref{fig:modelsTwoRules}, and we will get Model~1 as the unique solution. 
Notice that none of the three rules has targeted the word \la{}; still it has become unambiguous. 

Now, this is all very nice, but the present thesis is not called ``Implementing FSIG with a SAT-solver''. 
However, understanding the translation of rules to implications is vital to the rest of this thesis, and FSIG provides, arguably, a simpler starting point.
In the following sections, we discuss the concepts of conflict resolution and ordering of the rules. We will show a way to handle conflicts in pure FSIG, and consider two ways of emulating rule ordering in the SAT-encoding.


% We have given a minimal description of SAT-based implementation. 
% Many details are left vague: Do we enforce that all readings that are not targeted by rules will resolve to true? How do we treat ordering? 


\subsection{Solving conflicts in the parallel scheme}

As described in Section~\ref{sec:ordering}, the parallel FSIG behaves differently than the 
sequential CG: the rules are dependent on each other, and the order does not matter.
This prevents too hasty decisions, such as removing $\casaV$ before we know the status of \la{}. 
However, ignoring the order means that we miss significant information in the rule set. 
The truth is that pure FSIG is very brittle: each and every rule in the set must fit together, without the notion of order. The rule sequence in Figure~\ref{fig:ruleOrder}---taken from an actual grammar\footnote{\url{http://link.to/grammar}}---will be well-behaved in a strict and sequential CG. Its behaviour will be less clear in a heuristic and sequential CG, but in FSIG, it will definitely cause a conflict, rendering the whole grammar useless.

\begin{figure}
\centering
   \begin{verbatim}
   SECTION:good_rules
   REMOVE baz IF (-1 bar) ;

   SECTION:heuristic   
   REMOVE quux ;
   \end{verbatim}
\label{fig:ruleOrder}
\caption{Example from a XXX grammar}
\end{figure}

The order clearly demonstrates the course of action: ``if \todo{Foo} is preceded by \todo{Bar}, then remove/select \todo{Baz}; then, move on to other rules; finally, if \todo{Foo} is still ambiguous, select/remove \todo{Quux}.'' 
Comparing the success of CG to FSIG, one may speculate that the strictly sequential order is easier to understand---undeniably, its behaviour is more transparent. %As opposed to FSIG, the rules are ordered. As opposed to the heuristic order, the rules behave always the same way, regardless of the input.
If two rules target the same cohort, the first mentioned gets to apply, and removes the target. When the first rule has acted, the second rule is not even considered, because it would remove the last reading.
%After that, the second one would not even be considered, because of the default rule, which prohibits removing the last reading.

% In the carefully crafted examples, we have ignored the careful mode: \t{IF (-1C det)} `if the previous word is unambiguously determiner'. 
Ideally, both ways of grammar writing should yield similar results:
sequential CG rules are more imperative, and FSIG rules are more declarative.
The problem of conflicts in FSIG still remains---can we use an alternative way to handle conflicts in the unordered scheme?
%
% Recall the notion of heuristic rule order from Section~\ref{sec:ordering}: the rules are chosen based on how well they match the context. A longer rule is a more exact match than a shorter rule, and thus preferred. The heuristic rule order is still an order, though; it does not tell us what to do, when the two rules have already created clauses.
%
Recall the heuristic rule order from Section~\ref{sec:ordering}. The heuristic order is asking: ``out of all the rules that target this cohort, which one is the most exact match?'' If the competitors are \cgrule{REMOVE n IF (-1 prn)} and \cgrule{REMOVE v IF (-1 det) (1 adj)}, then the second one will win. However, if the rules are both as good a match, which happens in Figure~\ref{fig:modelsTwoRules}, we need to resort to mere guessing, or pick the one which is mentioned first in the rule set.

For an unordered scheme, we can ask a more complex question: ``out of all the rules that target this cohort, which one is a best fit \emph{with other rules that will apply to this whole sentence}?''
Answering this is beyond the means of previous FSIG engines \todo{is this so?}, but with a SAT-solver, we can answer this question. 

\paragraph{Maximisation} aka. ``FSIG as a MaxSAT-problem''

Each rule application to a concrete cohort produces a clause, and the whole rule set applied to the whole sentence produces a large formula.
In an ideal case, all the rules are well-behaved, and the whole formula is satisfiable. 
However, if the whole formula is unsatisfiable, we may still ask for an assignment that satisfies the maximum number of the clauses; that is, rule applications. 
If the grammar is good, we hope that the interaction between the appropriate
rules would make a large set of clauses that fit together, and the
inapplicable rule would not ``fit in''.
In the SAT-world, this means that the largest number of satisfiable clauses would include the group of well-fitting rules, and leave the odd rule out.

% This corresponds loosely to the common design pattern in
% CGs, where there is a number of rules with the same target, ordered
% such that more secure rules come first,
% with a catch-all rule with no condition as the last resort, to be
% applied if none of the previous has fired.
% The order-based heuristic in the traditional CG is replaced by a more
% holistic behaviour: if the rules conflict, discard the one that seems
% like an outlier.

Assuming our rules are \{\t{REMOVE v IF (-1 det)}, \t{REMOVE v IF (1 adj)}, \t{REMOVE n}\}, the revised algorithm goes as follows:

\begin{enumerate}
\item Apply \t{REMOVE v IF (-1 det)}
 \begin{itemize}
    \item Create a clause: $\laDet \Rightarrow \neg \casaV$
 \end{itemize}
\item Apply \t{REMOVE v IF (1 adj)} 
 \begin{itemize}
    \item Create a clause: $\grandeAdj \Rightarrow \neg \casaV$
 \end{itemize}
\item Apply \t{REMOVE n}
 \begin{itemize}
    \item Create a clause: $\neg \casaN$
 \end{itemize}

\item Solve with all clauses:
  $\{ \ob{\laDet \! \vee \laPrn, ...}^{\text{default rule}}, \ 
      \ob{\laDet \Rightarrow \neg \casaV}^{\t{REMOVE v IF (-1 det)}}, \ 
      \ob{\grandeAdj \Rightarrow \neg \casaV}^{\t{REMOVE v IF (1 adj)}}, \ 
      \ob{\neg \casaN}^{\t{REMOVE n}} \}$
\item No solution for all clauses: try to find a solution that satisfies maximally many clauses; however, default rule cannot be overridden.
\end{enumerate}

If a rule matches multiple cohorts, it creates a separate clause for each instance.
Thus, if the rule causes a conflict in only one cohort---say, we have another potential noun in the sentence, but it is not ambiguous with a verb, this is no problem. We can discard only the conflicting instances: we prevent \t{REMOVE n} from applying to $\casaN$, but it still may apply to other nouns.


This problem is known as Max-SAT \todo{cite}, and it is reducible to SAT; thus, it has the same properties, like it's NP-complete and stuff.
\todo{What is SAT+ actually doing? Some theory here.}


\subsection{Ordered scheme}
\label{sec:orderedScheme}

In the following, we show a modification to the parallel scheme, 
where the clauses are added to the formula incrementally, 
making sure that each new clause fits with the previously added.
%This allows us to emulate order, but still keep the benefits from the parallel
We contrast this with an alternative scheme; one that will be used in Chapter~\ref{chapterCGana}.



\paragraph{Adding the rules in order} We keep the parallel base: the cohort vectors are not manipulated between the rule applications, thus the 100\textsuperscript{th} rule still accesses the same variables as the first rule.
%the cohorts are encoded as vectors of variables, and the rules form implications at each application.
This means that all the benefits of parallel execution still hold: the three rules, which all target \emph{casa} may still disambiguate \emph{la}, without \emph{la} ever being the target.

In this modified scheme, we establish order by introducing the clauses to the SAT-solver one by one. 
Again, we have the same rule set: \{\t{REMOVE v IF (-1 det)}, \t{REMOVE v IF (1 adj)}, \t{REMOVE n}\}. Now the procedure goes as follows:

\begin{enumerate}
\item Apply \t{REMOVE v IF (-1 det)}
 \begin{itemize}
    \item Create a clause: $\laDet \Rightarrow \neg \casaV$
    \item Solve with previous clauses:
  $\{ \ob{\laDet \! \vee \laPrn, \ \casaN \vee \casaV, \  \grandeAdj}^{\text{default rule}}, \ 
      \ob{\laDet \Rightarrow \neg \casaV}^{\t{REMOVE v IF (-1 det)}} \}$
    \item Solution found: add new clause to the formula
 \end{itemize}
\item Apply \t{REMOVE v IF (1 adj)} 
 \begin{itemize}
    \item Create a clause: $\grandeAdj \Rightarrow \neg \casaV$
    \item Solve with previous clauses:
  $\{..., \laDet \Rightarrow \neg \casaV, \ 
      \ob{\grandeAdj \Rightarrow \neg \casaV}^{\t{REMOVE v IF (1 adj)}}  \}$
    \item Solution found: add new clause to the formula
 \end{itemize}
\item Apply \t{REMOVE n}
 \begin{itemize}
    \item Create a clause: $\neg \casaN$
    \item Solve with previous clauses:
      $\{ ..., \laDet \Rightarrow \neg \casaV, \ 
      \grandeAdj \Rightarrow \neg \casaV, \ 
      \ob{\neg \casaN}^{\t{REMOVE n}} \}$
  % $\{ \ob{\laDet \! \vee \laPrn, ...}^{\text{default rule}}, \ 
  %     \ob{\laDet \Rightarrow \neg \casaV}^{\t{REMOVE v IF (-1 det)}}, \ 
  %     \ob{\grandeAdj \Rightarrow \neg \casaV}^{\t{REMOVE v IF (1 adj)}}, \ 
    \item No solution: discard clause
 \end{itemize}
\end{enumerate}

The SAT-solver starts out with a prefix of rules, attempts to solve, and if it succeeds, only then it commits to the latest rule.
Similarly to the maximisation-based scheme, we create a clause for each instance of the rule application, and in the case of a conflict, we can only discard the clause targeting the offending cohort, not the whole sentence.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\def\newVar{$\text{\em word}'_\textsc{ RD}$}
\def\oldVar{$\text{\em word}_\textsc{\,RD}$}
\def\eqdef{\Coloneqq}
\def\invConds{\text{invalid condition}}
\def\onlyTrgLeft{\text{only target left}}

\paragraph{Modelling the state of the sentence} 

For the second option, we abandon the parallel encoding, and return to the semantics of good old sequential CG: rule application takes effect immediately, is irreversible, and only allows changes in the target.
To present this scheme, we start from something that is \emph{not} a SAT-problem: namely, manipulating Boolean expressions. The following encoding corresponds to the one in \cite{lager_nivre01} \todo{Do I need some formal proof that it corresponds to Lager \& Nivre, or can I just say that?}; however, we present it in a way that is syntactically closer to what we have seen so far.

As before, a sentence is a vector of cohorts, which is, in turn, a vector of variables representing the readings of the current cohort.
But now, we assume that each variable starts off as true: 
all those readings are true at the ``first round'', and the goal is to make more and more readings false, as more rules are applied.
At each rule application, we create a new variable \newVar{} for each targeted reading \oldVar{}.
The new variable \newVar{} is true iff 

\begin{tabular}{l l}
(a) \oldVar{} was true, and 
                             & (b) the rule cannot apply: this can be because \\
                                     & ~~~~-- its conditions do not hold, or \\
                                     & ~~~~-- it would remove the last reading.
\end{tabular}


\noindent In another notation, application of \t{REMOVE v IF (-1 det)} looks like the following:

$$\begin{array}{r l}
\text{New variable } \casa{}'_\v 
      & \Leftrightarrow \casaV\ 
        \wedge\: ( \; \ob{\neg\laDet}^{\invConds} 
        \vee  \ob{(\casaV \wedge \neg \casaN) }^{\onlyTrgLeft} ) \\
\end{array}$$


\noindent After the application, we replace each \oldVar with \newVar in the sentence vector; those variables that are not touched by the rule, will be carried over to the next round unchanged. A sentence vector may look like following after two rules which target verbs and one which targets nouns:


%\begin{figure}
$$\begin{array}{l @{~\rightarrow~} l}
1 & \{\laDet, \laPrn \} \\
2 & \{\casa{}''_\v, \casa{}'_\n \} \\
3 & \{ \grandeAdj \} \\
\end{array}$$
%\label{fig:after3Rules}
%\end{figure}

Now, we may ask, why is this not a SAT-problem? %We sure talk about Boolean values and build formulas.
The answer lies in the first step, where all variables start off as true. All the new variables, created from the rule applications, get their value immediately: $\casa{}'_\v \Leftrightarrow \grandeAdj \wedge \neg (\casaV \wedge \neg \casaN)$ just translates into $\casa{}'_\v \Leftrightarrow True \wedge \neg (True \wedge \neg True)$. There is nothing to decide, no search whatsoever; this problem is even simpler than the animal problem, where we at least had some choices to make.

Can we find something in this setup that would make an interesting SAT-problem? 
If this question is too intimidating, let us just ask ``can we make it into \emph{any} kind of SAT-problem''? 
Forget all ambition, just ask what we \emph{can} do.
We can go back to the first step: instead of all variables starting off as true, we can keep them unassigned. If we do that, where is the uncertainty?
All the other variables computed along the way depend on the original variables, so the question to the SAT-solver becomes: \emph{``Which readings were originally true?''}

Huh. That is an interesting question on its own right, but not very useful for a CG engine: we do know which readings were originally true, and we do not want the SAT-solver to be extra helpful and remove something that is targeted by no rule. But in Chapter~\ref{chapterCGana}, the new setup will allow us to find conflicts in the grammar, approximate generation and answer questions about expressivity. 
For the remainder of this chapter, however, we keep the parallel scheme and wrap up what we have started. 





% \subsection{Main differences between SAT-CG/FSIG/Lager98-almost-CG and good old sequential CG}

% \paragraph{Rules disambiguate more}
% Considering our example phrase and rules, the standard CG implementation
% can only remove readings from the target word (\texttt{prn} or
% \texttt{det}). The SAT-based implementation interprets the rules as
% ``determiner and verb together are illegal'', and is free to take action that concerns also the word in the condition (\texttt{n} or \texttt{v}).

% This behaviour is explained by simple properties of logical formulae.
% When the rules are applied to the text, they are translated into
% implications: \texttt{REMOVE prn IF (1 n)} becomes $\casaN \Rightarrow \neg \laPrn$,
%  which reads ``if the \texttt{n} reading for \emph{casa} is true, then
%  discard the \texttt{prn} reading for \emph{la}''.
% Any implication $a\,\Rightarrow\,b$ can be represented as a disjunction
% $\neg a\,\vee\,b$; intuitively, either the antecedent is false
% and the consequent can be anything, or the consequent is true and the
% antecedent can be anything.
% Due to this property, our rule translates into the disjunction 
% $\neg\casaN  \vee  \neg \laPrn$,
% which is also equivalent to another implication, 
% $\laPrn \Rightarrow \neg \casaN$.
% This means that the rules are logically flipped: \texttt{REMOVE prn IF
%   (1 n)} translates into the same logical formula as  \texttt{REMOVE n
%   IF (-1 prn)}. 
% A rule with more conditions corresponds to many rules, each condition
% taking its turn to be the target. % of removal or selection.

% % \begin{itemize}
% % \item [] \texttt{REMOVE n IF (-1 prn) ;} \\
% %          \texttt{REMOVE v IF (-1 det) ;}
% % \end{itemize}

% % SAT-based approach gives identical results with both sets of rules,
% % whereas the standard CG would remove one reading from \emph{casa} and leave \emph{la} ambiguous.
% % Testing this property with more complex rules and larger rule sets remains to be done.

% %Rules with more conditions translate into many rules; rules with negation become complements (\texttt{(*)-X} for \texttt{NOT X}). Rules which require the condition to be unambiguously tagged, don't have an equivalent flip in the standard CG.
% % We did not expect much practical benefits, save for realising that some rules are bad by having to think further what it implies,


% \paragraph{Cautious context is irrelevant}
% % Rather than waiting for a word to get disambiguated, the SAT solver starts by 
% % making assumptions (e.g. ``\emph{casa} is a noun'') and working under them,
% % discarding the assumption if it doesn't lead to a model that satisfies
% % all constraints.

% Traditional CG applies the rule set iteratively:
% some rules fire during the first iteration, either because their
% conditions do not require cautious context, or because some words are
% unambiguous to start with. This makes some more words unambiguous, and
% new rules can fire during the second iteration.

% In SAT-CG, the notion of cautious context is irrelevant. Instead of
% removing readings immediately,  each rule generates a  number of
% implications, and the SAT solver tries to find a model that will satisfy them. 

% The SAT-based approach only removes readings after it has enough
% evidence to do that. From the grammar writer perspective, this removes
% a burden of having to decide whether the rule should be cautious or
% not---the SAT solver will only take action the surrounding context
% supports the decision.

% % \todo{Unordered rules: also not applicable anymore to apply rules
% % iteratively; there's no ``this rule doesn't fire now but will after
% % applying X and Y'', it's all just implications ``this rule will fire
% % if this is true'' and let the SAT solver find if those rules can apply
% % peacefully to the same input.}




\section{Experiments}
\label{sec:eval}

In this section, we report experiments on the two modifications to the parallel scheme: maximisation-based, and ordering by committing to a prefix of rules.
We evaluate the performance against VISL CG-3 in accuracy and running time; in addition, we offer some preliminary observations on the effect of grammar writing.


For evaluation, we measure the performance against the state-of-the-art CG parser VISL CG-3.
% both in terms of accuracy and execution time.
SAT-CG fares slightly worse for accuracy, and significantly worse for execution time.
The results are presented in more detail in the following sections.
We include evaluation for three schemes: the original unordered, the original ordered, and the updated ordered.

%This suggests that our implementation should not compete with existing
%state-of-the-art, but rather it has value as a way of relating the CG
%formalism to wider context in the theory of computer science.
%In Section~\ref{sec:apps} we discuss more about possible applications.



\def\satcgMax{SAT-CG\textsubscript{Max}}
\def\satcgOrd{SAT-CG\textsubscript{Ord}}

\subsection{Performance against VISL CG-3}


We took a manually tagged
corpus\footnote{\url{https://svn.code.sf.net/p/apertium/svn/branches/apertium-swpost/apertium-en-es/es-tagger-data/es.tagged}}
containing approximately 22,000 words of Spanish news text, 
and a small constraint grammar\footnote{\url{https://svn.code.sf.net/p/apertium/svn/languages/apertium-spa/apertium-spa.spa.rlx}}, produced independently of the authors.
% We ignored substitute rules, but kept subreadings and unification, even though our implementation doesn't handle them.
We kept only \textsc{select} and \textsc{remove} rules, which left us 261 rules.
With this setup, we produced an ambiguous version of the tagged
corpus, and ran both SAT-CG and VISL CG-3 on it.
Treating the original corpus as the gold standard, the disambiguation
by  VISL CG-3 achieves F-score of 82.6 \%, ordered SAT-CG 81.5 \%  and
unordered SAT-CG 79.2 \%. 
We did not test with other languages or text genres due to the lack of
available gold standard.

\subsection{Execution time}

The worst-case complexity of SAT is exponential, whereas the standard
implementations of CG are polynomial, but with advances in SAT solving
techniques, the performance in the average case in practice is more feasible than in the previous works done in 90s--00s.

We tested the performance by parsing Don Quijote (384,155 words) with
the same Spanish grammars as in the previous experiment. 
Table~\ref{table:time} shows execution times compared to VISL CG-3;
\satcgMax is the parallel scheme with maximisation and
\satcgOrd is the parallel scheme where rule applications are introduced one by one.
% For both systems, the number of rules in the grammar affects the performance more than the word count.
From the SAT solving side, maximisation is the most costly operation. 
Emulating order is slightly faster, likely because the maximisation problems are smaller.
In any case, SAT does not seem to be the bottleneck: with 261 rules,
the maximisation function was called 147,253 times, and with 19 rules,
132,255 times, but 
%However, with both rule sets, half of the sentences in Don Quijote
%needed less than 6 calls of maximise, and 75 \% of the sentences
%needed less than 14.
the differences in the execution times are much larger, which suggests
that there are other reasons for the worse performance. 
This is to be expected, as SAT-CG is currently just a naive
proof-of-concept implementation with no optimisations.



\begin{table}
  \centering
  % \begin{tabular}{ c | c | c | c }
  %    \hline
  %    \textbf{\# rules} & \textbf{\satcgMax}  & \textbf{\satcgOrd} & \textbf{VISL CG-3} \\ \hline
  %     19   & 39.7s &  22.1s   & 4.2s\\ 
  %     99   & 1m34.1s & 1m14.9s & 6.1s \\ 
  %     261  & 2m54.1s & 2m31.6s & 10.7s \\ 

  \begin{tabular}{ c | c c | c c | c c }
      & \multicolumn{2}{c}{19 rules}  
                        &  \multicolumn{2}{c}{99 rules} 
                                          & \multicolumn{2}{c}{261 rules} \\ 
      & F-score & Time  & F-score & Time  & F-score & Time  \\ \hline
\textbf{VISL CG-3}
      & 82.6 \% & 4.2s  & ??? \% & 6.1s  & ??? \% & 10.7s \\
\textbf{\satcgOrd}
      & 81.5 \% & 22.1s & ??? \% &1m 15s & ??? \% & 2m 32s \\
\textbf{\satcgMax}
      & 79.2 \% & 39.7s & ??? \% &1m 34s & ??? \% & 2m 54s \\ 


  \end{tabular}
  \caption{F-scores and execution times for subsets of the Spanish grammar, disambiguating Don Quijote (384,155 words).}
  \label{table:time}
\end{table}

\subsection{Effect on grammar writing}

Throughout the implementation of SAT-CG, we have predicted that the more declarative features would influence the way rules are written. 
We hoped to combine the best parts of CG and FSIG: 
In addition, our modifications to the brittleness of FSIG have let us run CGs as FSIG; something that previous FSIG implementations do not allow.
As an inverse experiment, it would be interesting to take some large FSIG grammars \todo{find who has written them and cite} and run them with a CG engine, then compare the precision and recall.

Lacking an actual CG writer, it is hard to say whether this prediction holds or not.

We predict that less rules are needed; whether this holds in the order of thousands of rules remains to be tested. On the one hand, getting rid of ordering and cautious context could ease the task of the grammar writer, since it removes the burden of estimating the best sequence of rules and whether to make them cautious. On the other hand, lack of order can make the rules less transparent, and might not scale up for larger grammars.


The results in Table~\todo{make such table} suggests that that when running grammars that are written
with the traditional CG in mind, SAT-CG loses with both ordering
strategies, but emulating order fares better.

We also tested whether SAT-CG outperforms traditional CG with a
small rule set. With our best performing and most concise
grammar\footnote{\url{https://github.com/inariksit/cgsat/blob/master/data/spa\_smallset.rlx}}
of only 19 rules, both SAT-CG and VISL CG-3  achieve a F-score of
around 85 \%. This experiment is very small and might be explained by
overfitting or mere chance, but it seems to indicate that rules that
work well with SAT-CG are also good for traditional CG.
It was possible to attain a rule set for which the unordered SAT-CG
works better (\textless0.5 \%), but it required trying
subsequences of the 19-rule set in a brute force manner---this hardly
presents any real life use case.


Out of interest, we also manually flipped a small grammar and tested it against the original.
The personal experiences of doing this was that ``wow, people don't really mean what they write''. Like if you're drawing a portrait, try to flip your paper upside down or look at it as a mirror image; it is easier to see if the ears are wonky or the eyes are all over the place.


% Similar patterns were observed with small (\textless{}20) rule sets
% written by the authors; depending on the subset, SAT-CG and VISL CG-3 had
% a difference of at most $\Mypm$ 1.5 \%. 
% Introducing rules one by one up to 19, the
% performance improved in a very similar rate, with less than 0.5 \%
% difference between the systems at each new rule.
% We did not evaluate on other languages or text genres, due to lack of suitable test data.

% Additional tests could include plugging SAT-CG into Apertium
% translation pipeline, and comparing the translation quality.


Personal experiences about transparency (or lack thereof) and expressiveness.


The sequential application of traditional CG rules is good for
performance and transparency. When a rule takes action, the analyses
are removed from the sentence, and the next rules get the modified
sentence as input. 
% At the execution of rule, there is no way to go back to earlier rules and undo them. 
As a downside, there is no way to know which part comes directly from the
raw input and which part from applying previous rules.

In the examples, we have overlooked the C operator, and made a lot of noise how two rules without C can work together and who needs the damn C.
But SAT-CG is perfectly fine with C: it can start disambiguating, even if none of the rules is able to act on its own. 





\section{Summary}

In this section, we have accidentally reinvented FSIG, and then spent a lot of time trying to convince ourselves that it's still okay.

To alleviate the brittleness of FSIG, we developed two approaches to discard conflicting rule applications.
The first one is based on maximisation; trying to make as many clauses as possible apply, and the second one is based on order; introducing clauses one by one, and assuming that the previous clauses are true.

Interesting alternative for a CG engine, but loses in practicality: performance and lack of transparency for grammar writers.  
As a side note, using maximisation to solve conflicts could be of interest in a FSIG implementation.

There is potential in the ``wait before acting'' property. No decision is lost---we can use SAT-encoding to analyse CGs, rather than execute them.
As hinted in Section~\ref{sec:orderedScheme}, we will ultimately combine the CG semantics of unambiguous rule application, and leave the uncertainty for the question ``which analyses did we start with?''.



