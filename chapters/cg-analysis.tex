\chapter{Grammar analysis using SAT}
\label{chapterCGana}


In the previous chapter, we presented a tool.
In the current chapter, we will solve a problem.




Recall the design principles of CG from Section~\ref{sec:properties}: 
by design, the grammars are shallow and low-level.
There is no particular hierarchy between lexical, morphological,
syntactic or even semantic tags: individual rules can be written to address any
property, such as ``verb'', ``copula verb in first person singular'',
or ``the word form \emph{sailor}, preceded by \emph{drunken} anywhere in the
sentence''. This makes it possible to treat very particular edge
cases without touching the more general rule: we would simply write
the narrow rule first (``if noun AND \emph{sailor}''), and introduce
the general rule (``if noun'') later.


However, this design is not without problems. As CGs grow larger, it
gets harder to keep track of all the rules and their interaction.
Despite this well-known issue, there has not been a tool that would help 
grammar writers to detect conflicting rules.
Following the idea further, the tool could give feedback that is not 
restricted to conflicts, but also other features that are helpful 
in the process of writing grammar.
Given the rules in Figure~\ref{fig:infrules}, a grammar writer may 
ask the following questions.



\begin{itemize}
\item Are all the rules distinct? (e.g. \texttt{Para} and \texttt{De} may be included in \texttt{Prep})
\item Could two or more rules be merged? (e.g. \texttt{SELECT Inf IF -1 Prep OR Vai OR Vbmod ...})
\item What is the best order for the rules?
\item Generate a sequence that triggers rule(s) $R$ but not rule(s) $R'$. 
\end{itemize}

%%%%%


\begin{figure}[t]
\ttfamily
\centering
\begin{tabular}{l | l  l}
SELECT Inf IF ... & \multicolumn{2}{c}{SELECT V + Prs/Imprt + Act + Neg IF ...} \\
~~(-1 Prep) (0C V) ;       & (*-1C Negv LINK NOT *1 Vfin)  & (NOT *-1 Niin OR Neg)  \\
~~(-1 Para OR De) (0C V) ; & (NOT 0 N) (NOT 0 Pron)        & (*-1C Negv \\
~~(-1C Vbmod) (0C V) ;     & (NOT *1 Neg) (NOT *-1 Neg)    &  ~~LINK NOT 0 Imprt \\
~~(-1C Vai) ;              & (NOT 0 Pass) (NOT *-1 Niin)   &  ~~LINK NOT *1 Vfin OR CLB?) \\
~~(-1C Vbmod) (0 Ser) ;    & (*-1C Negv LINK NOT *1 CLB?)  & (NOT 0 N OR Pron OR Pass) \\
~~(-1C Ter/de) ;           & (*-1C Negv LINK NOT 0 Imprt) ;  & (NOT *1 Neg) ; \\

\end{tabular}

\caption{Left: rules to select infinitive in Portuguese. 
        Right: two versions of a condition in Finnish.}

\label{fig:infrules}
\end{figure}

The chapter follows with introduction of related work: namely, corpus-based methods to aid grammar writing, and automatic optimisation of a complete, human-written grammar. We continue by presenting our solution, along with a working implementation, and finally, evaluate its performance.


\todo{From now on, the text is more of an early draft, and I intend change it a lot! Read if you want, but be prepared that it will change.}

\section{Related work}
\label{sec:CGanaRelated}

We combine elements from the following aspects of CG research:

\begin{itemize}
\item Corpus-based methods in manual grammar development \cite{voutilainen2004}
\item Optimising hand-written CGs~\cite{bick2013tuning}
\end{itemize}

In addition, there is a large body of research on automatically
inducing rules, e.g. \cite{inducing_cg1996}, \cite{lindberg_eineborg98ilp},
\cite{lager01transformation} and \cite{asfrent14}.
However, since our work is aimed to aid the process of hand-crafting rules, we omit those works from our discussion.


\paragraph{Corpus-based methods in manual grammar development}

Hand-annotated corpora are commonly used in the development of CGs, because they give immediate feedback whether a new rule increases or decreases accuracy \cite{voutilainen2004}.
This helps the grammar writer to arrange the rules in appropriate sections, with safest and most effective rules coming first.
However, this method will not notice a missed opportunity or a grammar-internal conflict, nor suggest ways to improve.

\cite{voutilainen2004} gives a detailed account about best practices of grammar writing and efficient use of corpora to aid the grammar development.
For a language with no free or tagset-compatible corpus available, \cite{tyers_reynolds2015} describe a method where they apply their rules to unannotated Wikipedia texts and pick 100 examples at random for manual check.

CG rules are usually arranged in sections, and run in the following manner. 
First apply rules from section 1, and repeat until nothing changes in the text. Then apply rules from sections 1--2, then 1--3 and so on, until the set includes all rules.
The best strategy is to place the safest and most effective rules in the first sections,
so that they make way for the following, more heuristic and less safe rules to act on.

A representative corpus is arguably the best way to get concrete numbers---how many times a rule applied and how often it was correct---and to arrange the rules in sections based on that feedback.
However, this method will not notice a missed opportunity or a grammar-internal conflict, nor suggest ways to improve.

\cite{voutilainen2004} state that the around 200 rules are probably enough to resolve 50--75 \% of ambiguities in the corpus used in the development. 
\todo{move this bit to the end/discussion? \\
This figure is nice and encouraging. It's very much thanks to Zipf's law: we can add rules that target the most frequent \emph{tokens}, thus disambiguating a high number of word forms. However, this does not guarantee a coherent whole of rules. 
While the coverage information is easy to obtain from a corpus, there is no tool that would aid grammar writers to write a grammar with a wide coverage of different linguistic phenomena.}


\paragraph{Automatic optimisation of hand-written grammars }

The corpus-based method can tell the effect of each single rule at their place in the rule sequence, and leaves the grammar writer to make changes in the grammar.
\cite{bick2013tuning} modifies the grammar automatically, by trying
out different rule orders and altering the contexts of the rules. 
Bick reports error reduction of 7--15\% compared to the original grammars.

This is a valuable tool, especially for grammars that are so big that it's hard to keep track manually. A program can try all combinations whereas trying to make sense out of a huge set of rules would be hard for humans.
As a downside, the grammar writer will likely not know why exactly does the tuned grammar perform better.


\section{Analysing CGs}
\label{sec:sectionCGana}

Now let's get to the fun. We start by defining a conflict, and present our solution.

\paragraph{Conflict}

We define \emph{conflict} as follows: a list of rules $R$ is in conflict with the rule $r$, if applying $R$ makes it impossible to apply $r$, regardless of input.
Some examples of conflicts follow:

\begin{itemize}
\item If two equivalent rules $r$ and $r'$ occur in the grammar, the second occurrence will be disabled by the first
\item Rule $r$ selects something in a context, and $r'$ removes it
\item A list of rules $R$ removes something from the context of a rule $r'$, so $r'$ can never apply
\item A rule $r$ has an internal conflict, such as non-existent
tag combination, or contradictory requirements for a context word
\end{itemize}
In the above examples, $R$ can also be a single rule or a list of rules: for instance, if one rule removes a verb in
context $C$, and another in context $\neg C$, together these rules
remove a verb in all possible cases, disabling any future rule that
targets verbs.

% While rule-internal conflicts can be detected by simpler means, taking
% care of rule interaction requires a {\em semantic} rather than a {\em
%  syntactic} analysis.
% In order to find effects of rule interaction, we must keep track of
% the possible sentences at each step. After each rule, we have two
% possibilities: the rule fires, or it does not fire. In case the rule does
% not fire, we have again two options: either its conditions are not met,
% or its target is the only remaining analysis. 

\paragraph{Solution}
Some hints for the solution have been dropped along the way. 
In Section~\ref{sec:orderedScheme}, we found how to ask the question 
``Which readings were originally true?'' Now match it to the definition of conflict: ``applying $R$ makes it impossible to apply $r$ \emph{regardless of input}''.
In a nutshell, we are going to show the absence of a conflict by creating 
a sequence where $r$ can apply after $R$; conversely, we detect a conflict by 
showing that such sequence cannot be created.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\def\newVar{$\text{\em word}'_\textsc{ RD}$}
\def\oldVar{$\text{\em word}_\textsc{\,RD}$}
\def\eqdef{\Coloneqq}
\def\invConds{\text{invalid condition}}
\def\onlyTrgLeft{\text{only target left}}

\subsection{Sequential scheme}
\label{sec:orderedScheme}

For a moment, we abandon the parallel encoding and return to the semantics of good old sequential CG: rule application takes effect immediately, is irreversible, and only allows changes in the target.
To present this scheme, we start from something that is \emph{not} a SAT-problem: namely, manipulating Boolean expressions. The following encoding corresponds to the one in \cite{lager_nivre01} \todo{Do I need some formal proof that it corresponds to Lager \& Nivre, or can I just say that?}; however, we present it in a way that is syntactically closer to what we have seen so far.

As before, a sentence is a vector of cohorts, which is, in turn, a vector of variables representing the readings of the current cohort.
But now, we assume that each variable starts off as true: 
all those readings are true at the ``first round'', and the goal is to make more and more readings false, as more rules are applied.
At each rule application, we create a new variable \newVar{} for each targeted reading \oldVar{}.
The new variable \newVar{} is true iff 

\begin{figure}[h]
\begin{tabular}{l l}
(a) \oldVar{} was true, and 
                             & (b) the rule cannot apply: this can be because \\
                                     & ~~~~-- its conditions do not hold, or \\
                                     & ~~~~-- it would remove the last reading.
\end{tabular}
\end{figure}

\noindent In another notation, application of \t{REMOVE v IF (-1 det)} looks like the following:

$$\begin{array}{r l}
\text{New variable } \casa{}'_\v 
      & \Leftrightarrow \casaV\ 
        \wedge\: ( \; \ob{\neg\laDet}^{\invConds} 
        \vee  \ob{(\casaV \wedge \neg \casaN) }^{\onlyTrgLeft} ) \\
\end{array}$$


\noindent After the application, we replace each \oldVar with \newVar in the sentence vector; those variables that are not touched by the rule, will be carried over to the next round unchanged. A sentence vector may look like following after two rules which target verbs and one which targets nouns:


%\begin{figure}
$$\begin{array}{l @{~\rightarrow~} l}
1 & \{\laDet, \laPrn \} \\
2 & \{\casa{}''_\v, \casa{}'_\n \} \\
3 & \{ \grandeAdj \} \\
\end{array}$$
%\label{fig:after3Rules}
%\end{figure}

Now, we may ask, why is this not a SAT-problem? %We sure talk about Boolean values and build formulas.
The answer lies in the first step, where all variables start off as true. All the new variables, created from the rule applications, get their value immediately: $\casa{}'_\v \Leftrightarrow \grandeAdj \wedge \neg (\casaV \wedge \neg \casaN)$ just translates into $\casa{}'_\v \Leftrightarrow True \wedge \neg (True \wedge \neg True)$. There is nothing to decide, no search whatsoever; this problem is even simpler than the animal problem, where we at least had some choices to make.

Can we find something in this setup that would make an interesting SAT-problem? 
If this question is too intimidating, let us just ask ``can we make it into \emph{any} kind of SAT-problem''? 
Forget all ambition, just ask what we \emph{can} do.
We can go back to the first step: instead of all variables starting off as true, we can keep them unassigned. If we do that, where is the uncertainty?
All the other variables computed along the way depend on the original variables, so the question to the SAT-solver becomes: \emph{``Which readings were originally true?''}

% Huh. That is an interesting question on its own right, but not very useful for a CG engine: we do know which readings were originally true, and we do not want the SAT-solver to be extra helpful and remove something that is targeted by no rule. But in Chapter~\ref{chapterCGana}, the new setup will allow us to find conflicts in the grammar, approximate generation and answer questions about expressivity. 
% For the remainder of this chapter, however, we keep the parallel scheme and wrap up what we have started. 



\todo{Reached the end of new content! From here on it's just the old paper copypasted.}


\subsection{Preliminaries}

Our analysis operates on a rule $r$, which is preceded by a list of rules $R$, and is concerned with answering the following question: ``Does there exist an input sentence $S$ that can trigger rule $r$, even after passing all rules $R$ that came before $r$?''
Instead of concrete sentences from a corpus, we apply rules on {\em symbolic sentences}:
every cohort contains every possible reading, and rule applications are responsible for shaping the sentence into a concrete one.

Before we can do any analysis any of the rules, we need to find out what the set of all possible readings of a word is. We can do this by extracting this information from a lexicon, but there are other ways too. In our experiments, the number of readings has ranged from about 300 to about 9000. 

Furthermore, when we analyse a rule $r$, we need to decide the {\em width} $w(r)$ of the rule $r$: How many different words should there be in a sentence that can trigger $r$? Most often, $w(r)$ can be easily determined by looking at how far away the rule context indexes in the sentence relative to the target. For example, in the rule mentioned in the introduction, the width is 2.

If the context contains a \verb!*! (context word can be anywhere),
we may need to make an approximation of $w(r)$, which may result in false positives or negatives later on in the analysis.
%we create sentences that are up to 3 words wider than the context without \verb!*!, and try them all.


%%%%%%%
% Too verbose beginning

% In the previous chapter, we have seen the SAT encoding of CG used to
% create a CG engine.
% We evaluated our engine against the state-of-the-art VISL CG-3, using
% the same grammar and same gold standard corpus.
% Unsurprisingly, we got worse results when using the SAT-based parallel
% implementation on grammars that were written for an imperative and
% sequential CG engine. 
% Given that most real grammars out there are written in such way, 
% using SAT in the CG engine offers little practical use.

% On the other hand, SAT-based implementation offers benefits that are
% out of reach for the standard CG or FSIG implementations. 

% By design, the effect of each rule is retained, because it makes a difference 
% whether to execute a rule that appears later. This means that we can use our
% implementation for analysing the grammar.

% In the implementation described in the previous paragraph, we analysed
% some real input sentences, and generated clauses of the rules that
% applied to those particular sentences. If there is a word that is
% analysed as n or v, it can only match rules that target those analyses
% (and is surrounded by appropriate context).

% Now, we operate on \emph{symbolic sentences}. We start from a
% situation where each word in the sentence can have any analysis: this
% means that every rule potentially applies to every word. This
% combination of rule application starts narrowing down the potential
% sentence.
% The rules are interpreted as more abstract and declarative:
% \texttt{REMOVE verb IF -1 det} does not just check if a particular
% word is verb, it prohibits a combination of determiner followed by
% verb \emph{anywhere}. The restriction can show in various ways, 
% %if another rule requires the 3rd word of the sentence to be determiner, then the 4th may not be a verb. If a rule requires
% and must be in sync with other restrictions.

% If it turns out that there is no symbolic sentence that can satisfy a
% number of rules, this means that there is a conflict among the
% rules. In the following chapter, we will give examples of such
% conflicts and describe how to detect them.


