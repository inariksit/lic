\chapter{Grammar analysis using SAT}
\label{chapterCGana}


In the previous chapter, we have presented a tool.
In the current chapter, we will solve a problem.




Recall the design principles of CG from Section~\ref{sec:properties}: 
by design, the grammars are shallow and low-level.
There is no particular hierarchy between lexical, morphological,
syntactic or even semantic tags: individual rules can be written to address any
property, such as ``verb'', ``copula verb in first person singular'',
or ``the word form \emph{sailor}, preceded by \emph{drunken} anywhere in the
sentence''. This makes it possible to treat very particular edge
cases without touching the more general rule: we would simply write
the narrow rule first (``if noun AND \emph{sailor}''), and introduce
the general rule (``if noun'') later.


However, this design is not without problems. As CGs grow larger, it
gets harder to keep track of all the rules and their interaction.
Despite this well-known issue, there has not been a tool that would help 
grammar writers to detect conflicting rules.
Following the idea further, the tool could give feedback that is not 
restricted to conflicts, but also other features that are helpful 
in the process of writing grammar.
Given the rules in Figure~\ref{infrules}~and~\ref{fig:regroup},, a grammar writer may 
ask the following questions.



\begin{itemize}
\item Are all the rules distinct? (e.g. \texttt{Para} and \texttt{De} may be included in \texttt{Prep})
\item Could two or more rules be merged? (e.g. \texttt{SELECT Inf IF -1 Prep OR Vai OR Vbmod ...})
\item What is the best order for the rules?
\item Generate a sequence that triggers rule(s) $R$ but not rule(s) $R'$. 
\end{itemize}

%%%%%

\begin{figure}[t]
\begin{center}

\begin{itemize}
\item[]
\begin{verbatim}SELECT Inf IF (-1 Para OR De) (0C V) ;
SELECT Inf IF (-1 Prep) (0C V) ;
SELECT Inf IF (-1C Vai) ;
SELECT Inf IF (-1C Vbmod) (0C V) ;
SELECT Inf IF (-1C Ter/de) ;
SELECT Inf IF (-1C Vbmod) (0 Ser) ;
\end{verbatim}
\end{itemize}

\caption{Rules to select infinitive in Portuguese.}
\end{center}
\label{fig:infrules}
\end{figure}

The chapter follows with introduction of related work: namely, corpus-based methods to aid grammar writing, and automatic optimisation of a complete, human-written grammar. We continue by presenting our solution, along with a working implementation, and finally, evaluate its performance.



\begin{figure}[t]
\centering
\begin{itemize}

\item[]\texttt{SELECT V + Prs/Imprt + Act + Neg}

\item[\texttt{IF}]
\begin{verbatim}(*-1C Negv LINK NOT *1 Vfin/PrsPrc/Inf) 
(NOT 0 N) (NOT 0 Pron) 
(NOT *1 Neg) (NOT *-1 Neg)
(NOT 0 Pass) (NOT *-1 Niin) 
(*-1C Negv LINK NOT *1 CLB?) 
(*-1C Negv LINK NOT 0 Imprt) ; 
\end{verbatim}

\item[\texttt{IF}]
\begin{verbatim}(NOT *-1 Niin OR Neg)  
(*-1C Negv
  LINK NOT 0 Imprt
  LINK NOT *1 Vfin/PrsPrc/Inf OR CLB?) 
(NOT 0 N OR Pron OR Pass) 
(NOT *1 Neg) ;
\end{verbatim}
\end{itemize}

\caption{Two versions of a condition in Finnish.}

\label{fig:regroup}
\end{figure}


\section{Related work}
\label{sec:CGanaRelated}

We combine elements from the following aspects of CG research:

\begin{itemize}
\item Corpus-based methods in manual grammar development \cite{voutilainen2004}
\item Optimising hand-written CGs~\cite{bick2013tuning}
\end{itemize}

In addition, there is a large body of research on automatically
inducing rules, e.g. \cite{inducing_cg1996}, \cite{lindberg_eineborg98ilp},
\cite{lager01transformation} and \cite{asfrent14}.
However, since our work is aimed to aid the process of hand-crafting rules, we omit those works from our discussion.


\paragraph{Corpus-based methods in manual grammar development}

Hand-annotated corpora are commonly used in the development of CGs, because they give immediate feedback whether a new rule increases or decreases accuracy \cite{voutilainen2004}.
This helps the grammar writer to arrange the rules in appropriate sections, with safest and most effective rules coming first.
However, this method will not notice a missed opportunity or a grammar-internal conflict, nor suggest ways to improve.

\cite{voutilainen2004} gives a detailed account about best practices of grammar writing and efficient use of corpora to aid the grammar development.
For a language with no free or tagset-compatible corpus available, \cite{tyers_reynolds2015} describe a method where they apply their rules to unannotated Wikipedia texts and pick 100 examples at random for manual check.

CG rules are usually arranged in sections, and run in the following manner. 
First apply rules from section 1, and repeat until nothing changes in the text. Then apply rules from sections 1--2, then 1--3 and so on, until the set includes all rules.
The best strategy is to place the safest and most effective rules in the first sections,
so that they make way for the following, more heuristic and less safe rules to act on.

A representative corpus is arguably the best way to get concrete numbers---how many times a rule applied and how often it was correct---and to arrange the rules in sections based on that feedback.
However, this method will not notice a missed opportunity or a grammar-internal conflict, nor suggest ways to improve.

\cite{voutilainen2004} state that the around 200 rules are probably enough to resolve 50--75 \% of ambiguities in the corpus used in the development. 
\todo{move this bit to the end/discussion? \\
This figure is nice and encouraging. It's very much thanks to Zipf's law: we can add rules that target the most frequent \emph{tokens}, thus disambiguating a high number of word forms. However, this does not guarantee a coherent whole of rules. 
While the coverage information is easy to obtain from a corpus, there is no tool that would aid grammar writers to write a grammar with a wide coverage of different linguistic phenomena.}


\paragraph{Automatic optimisation of hand-written grammars }

The corpus-based method can tell the effect of each single rule at their place in the rule sequence, and leaves the grammar writer to make changes in the grammar.
\cite{bick2013tuning} modifies the grammar automatically, by trying
out different rule orders and altering the contexts of the rules. 
Bick reports error reduction of 7--15\% compared to the original grammars.

This is a valuable tool, especially for grammars that are so big that it's hard to keep track manually. A program can try all combinations whereas trying to make sense out of a huge set of rules would be hard for humans.
As a downside, the grammar writer will likely not know why exactly does the tuned grammar perform better.


\section{Analysing CGs}
\label{sec:sectionCGana}

Now let's get to the fun. We start by defining a conflict, and present our solution.

\paragraph{Conflict}

We define \emph{conflict} as follows: a set of rules $R$ is in conflict with the rule $r$, if applying $R$ makes it impossible to apply $r$, regardless of input.
Some examples of conflicts follow:

\begin{itemize}
\item If two equivalent rules $r$ and $r'$ occur in the grammar, the second occurrence will be disabled by the first
\item Rule $r$ selects something in a context, and $r'$ removes it
\item A list of rules $R$ removes something from the context of a rule $r'$, so $r'$ can never apply
\item A rule $r$ has an internal conflict, such as non-existent
tag combination, or contradictory requirements for a context word
\end{itemize}
In the above examples, $R$ can also be a single rule or a list of rules: for instance, if one rule removes a verb in
context $C$, and another in context $\neg C$, together these rules
remove a verb in all possible cases, disabling any future rule that
targets verbs.

% While rule-internal conflicts can be detected by simpler means, taking
% care of rule interaction requires a {\em semantic} rather than a {\em
%  syntactic} analysis.
% In order to find effects of rule interaction, we must keep track of
% the possible sentences at each step. After each rule, we have two
% possibilities: the rule fires, or it does not fire. In case the rule does
% not fire, we have again two options: either its conditions are not met,
% or its target is the only remaining analysis. 

\paragraph{Solution}
Some hints for the solution have been dropped along the way. 
In Section~\ref{sec:orderedScheme}, we found how to ask the question 
``Which readings were originally true?'' Now match it to the definition of conflict: ``... impossible to apply ... \emph{regardless of input}''.
In a nutshell, we are going to show the absence of a conflict by creating 
a sequence where $r'$ can apply after $r$; conversely, we detect a conflict by 
showing that such sequence cannot be created.

\todo{Reached the end of new content! I removed the old paper from here.}




%%%%%%%
% Too verbose beginning

% In the previous chapter, we have seen the SAT encoding of CG used to
% create a CG engine.
% We evaluated our engine against the state-of-the-art VISL CG-3, using
% the same grammar and same gold standard corpus.
% Unsurprisingly, we got worse results when using the SAT-based parallel
% implementation on grammars that were written for an imperative and
% sequential CG engine. 
% Given that most real grammars out there are written in such way, 
% using SAT in the CG engine offers little practical use.

% On the other hand, SAT-based implementation offers benefits that are
% out of reach for the standard CG or FSIG implementations. 

% By design, the effect of each rule is retained, because it makes a difference 
% whether to execute a rule that appears later. This means that we can use our
% implementation for analysing the grammar.

% In the implementation described in the previous paragraph, we analysed
% some real input sentences, and generated clauses of the rules that
% applied to those particular sentences. If there is a word that is
% analysed as n or v, it can only match rules that target those analyses
% (and is surrounded by appropriate context).

% Now, we operate on \emph{symbolic sentences}. We start from a
% situation where each word in the sentence can have any analysis: this
% means that every rule potentially applies to every word. This
% combination of rule application starts narrowing down the potential
% sentence.
% The rules are interpreted as more abstract and declarative:
% \texttt{REMOVE verb IF -1 det} does not just check if a particular
% word is verb, it prohibits a combination of determiner followed by
% verb \emph{anywhere}. The restriction can show in various ways, 
% %if another rule requires the 3rd word of the sentence to be determiner, then the 4th may not be a verb. If a rule requires
% and must be in sync with other restrictions.

% If it turns out that there is no symbolic sentence that can satisfy a
% number of rules, this means that there is a conflict among the
% rules. In the following chapter, we will give examples of such
% conflicts and describe how to detect them.


